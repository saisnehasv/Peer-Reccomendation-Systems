{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer Recommendation System\n",
    "\n",
    "Course: SI 670: Applied Machine Learning\n",
    "\n",
    "Name : Yuganshi Agrawal  \n",
    "uniqname: yuganshi\n",
    "\n",
    "Name : Sai Sneha Siddapura Venkataramappa  \n",
    "uniqname: saisneha\n",
    "\n",
    "### Notebook 01: Data Preparation\n",
    "\n",
    "This notebook loads, cleans, and validates the OULAD dataset.\n",
    "\n",
    "**Inputs:**\n",
    "- Raw OULAD CSV files from `data/raw/`\n",
    "\n",
    "**Outputs:**\n",
    "- Cleaned datasets saved to `data/processed/`\n",
    "- Train/test split of students saved\n",
    "- Data quality report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware Configuration:\n",
      "  CPUs available: 32\n",
      "  Device: cuda\n",
      "  GPUs accessible: 4\n",
      "    GPU 0: Error - CUDA call failed lazily at initialization with err\n",
      "    GPU 1: Error - CUDA call failed lazily at initialization with err\n",
      "    GPU 2: Error - CUDA call failed lazily at initialization with err\n",
      "    GPU 3: Error - CUDA call failed lazily at initialization with err\n",
      "\n",
      "Parallel Configuration:\n",
      "  Workers: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "if 'CUDA_VISIBLE_DEVICES' not in os.environ:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2'\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)\n",
    "random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "\n",
    "# Cell 2: Hardware detection\n",
    "N_CPU = mp.cpu_count()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_GPU = 0\n",
    "\n",
    "print(\"Hardware Configuration:\")\n",
    "print(f\"  CPUs available: {N_CPU}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    try:\n",
    "        N_GPU = torch.cuda.device_count()\n",
    "        print(f\"  GPUs accessible: {N_GPU}\")\n",
    "        \n",
    "        for i in range(N_GPU):\n",
    "            try:\n",
    "                name = torch.cuda.get_device_name(i)\n",
    "                print(f\"    GPU {i}: {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    GPU {i}: Error - {str(e)[:50]}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  GPU detection failed: {e}\")\n",
    "        print(\"  Falling back to CPU\")\n",
    "        DEVICE = 'cpu'\n",
    "        N_GPU = 0\n",
    "\n",
    "print()\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    N_WORKERS = min(8, N_CPU // 2)\n",
    "else:\n",
    "    N_WORKERS = max(1, N_CPU - 2)\n",
    "\n",
    "print(f\"Parallel Configuration:\")\n",
    "print(f\"  Workers: {N_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure created\n",
      "  Raw data: ../670-Project/data/raw\n",
      "  Processed data: ../670-Project/data/processed\n",
      "  Features: ../670-Project/data/features\n",
      "  Models: ../670-Project/models\n",
      "  Results: ../670-Project/results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('../670-Project')\n",
    "DATA_RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "DATA_PROCESSED_DIR = BASE_DIR / 'data' / 'processed'\n",
    "DATA_FEATURES_DIR = BASE_DIR / 'data' / 'features'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(MODELS_DIR / 'checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "(MODELS_DIR / 'embeddings').mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS_DIR / 'metrics').mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS_DIR / 'predictions').mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS_DIR / 'analysis').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Directory structure created\")\n",
    "print(f\"  Raw data: {DATA_RAW_DIR}\")\n",
    "print(f\"  Processed data: {DATA_PROCESSED_DIR}\")\n",
    "print(f\"  Features: {DATA_FEATURES_DIR}\")\n",
    "print(f\"  Models: {MODELS_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Holdout fraction: 0.1\n",
      "  Random seed: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HOLDOUT_STUDENT_FRAC = 0.10\n",
    "\n",
    "EXPECTED_FILES = [\n",
    "    'studentInfo.csv',\n",
    "    'studentVle.csv',\n",
    "    'vle.csv',\n",
    "    'assessments.csv',\n",
    "    'studentAssessment.csv',\n",
    "    'courses.csv',\n",
    "    'studentRegistration.csv'\n",
    "]\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Holdout fraction: {HOLDOUT_STUDENT_FRAC}\")\n",
    "print(f\"  Random seed: {RNG_SEED}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load all OULAD CSV files with validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for required files...\n",
      "  Found: studentInfo.csv\n",
      "  Found: studentVle.csv\n",
      "  Found: vle.csv\n",
      "  Found: assessments.csv\n",
      "  Found: studentAssessment.csv\n",
      "  Found: courses.csv\n",
      "  Found: studentRegistration.csv\n",
      "\n",
      "All required files found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for required files...\")\n",
    "missing_files = []\n",
    "for filename in EXPECTED_FILES:\n",
    "    filepath = DATA_RAW_DIR / filename\n",
    "    if not filepath.exists():\n",
    "        missing_files.append(filename)\n",
    "    else:\n",
    "        print(f\"  Found: {filename}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nERROR: Missing files: {missing_files}\")\n",
    "    print(f\"Please place OULAD CSV files in: {DATA_RAW_DIR}\")\n",
    "    raise FileNotFoundError(f\"Missing required files: {missing_files}\")\n",
    "\n",
    "print(\"\\nAll required files found\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f724be9f76c4c0eb43aa02f6b5ac338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading CSVs:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\n",
    "datasets = {}\n",
    "load_times = {}\n",
    "\n",
    "for filename in tqdm(EXPECTED_FILES, desc=\"Loading CSVs\"):\n",
    "    name = filename.replace('.csv', '')\n",
    "    filepath = DATA_RAW_DIR / filename\n",
    "    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    datasets[name] = pd.read_csv(filepath)\n",
    "    load_times[name] = time.time() - start\n",
    "\n",
    "student_info = datasets['studentInfo']\n",
    "student_vle = datasets['studentVle']\n",
    "vle = datasets['vle']\n",
    "assessments = datasets['assessments']\n",
    "student_assessment = datasets['studentAssessment']\n",
    "courses = datasets['courses']\n",
    "student_registration = datasets['studentRegistration']\n",
    "\n",
    "print(\"\\nLoad complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "  studentInfo              :     32,593 rows,  12 columns (loaded in 0.04s)\n",
      "  studentVle               : 10,655,280 rows,   6 columns (loaded in 4.08s)\n",
      "  vle                      :      6,364 rows,   6 columns (loaded in 0.01s)\n",
      "  assessments              :        206 rows,   6 columns (loaded in 0.00s)\n",
      "  studentAssessment        :    173,912 rows,   5 columns (loaded in 0.06s)\n",
      "  courses                  :         22 rows,   3 columns (loaded in 0.00s)\n",
      "  studentRegistration      :     32,593 rows,   5 columns (loaded in 0.02s)\n",
      "\n",
      "Key statistics:\n",
      "  Unique students: 28,785\n",
      "  Unique modules: 7\n",
      "  Unique presentations: 4\n",
      "  Module-presentation pairs: 22\n",
      "  Total VLE interactions: 10,655,280\n",
      "  Total assessments: 206\n",
      "  Total assessment submissions: 173,912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset sizes:\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"  {name:25s}: {len(df):>10,} rows, {len(df.columns):>3} columns (loaded in {load_times[name]:.2f}s)\")\n",
    "print()\n",
    "\n",
    "print(\"Key statistics:\")\n",
    "print(f\"  Unique students: {student_info['id_student'].nunique():,}\")\n",
    "print(f\"  Unique modules: {student_info['code_module'].nunique()}\")\n",
    "print(f\"  Unique presentations: {student_info['code_presentation'].nunique()}\")\n",
    "print(f\"  Module-presentation pairs: {student_info.groupby(['code_module', 'code_presentation']).ngroups}\")\n",
    "print(f\"  Total VLE interactions: {len(student_vle):,}\")\n",
    "print(f\"  Total assessments: {len(assessments)}\")\n",
    "print(f\"  Total assessment submissions: {len(student_assessment):,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value analysis:\n",
      "\n",
      "studentInfo:\n",
      "  imd_band: 1,111 (3.41%)\n",
      "\n",
      "vle:\n",
      "  week_from: 5,243 (82.39%)\n",
      "  week_to: 5,243 (82.39%)\n",
      "\n",
      "assessments:\n",
      "  date: 11 (5.34%)\n",
      "\n",
      "studentAssessment:\n",
      "  score: 173 (0.10%)\n",
      "\n",
      "studentRegistration:\n",
      "  date_registration: 45 (0.14%)\n",
      "  date_unregistration: 22,521 (69.10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value analysis:\")\n",
    "print()\n",
    "\n",
    "quality_report = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    \n",
    "    if missing.sum() > 0:\n",
    "        print(f\"{name}:\")\n",
    "        for col in missing[missing > 0].index:\n",
    "            print(f\"  {col}: {missing[col]:,} ({missing_pct[col]:.2f}%)\")\n",
    "        print()\n",
    "    \n",
    "    quality_report[name] = {\n",
    "        'total_rows': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'missing_values': missing.to_dict(),\n",
    "        'missing_percentages': missing_pct.to_dict()\n",
    "    }\n",
    "\n",
    "if not any(df.isnull().sum().sum() > 0 for df in datasets.values()):\n",
    "    print(\"No missing values found in any dataset\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate analysis:\n",
      "\n",
      "studentVle:\n",
      "  Total duplicates: 787,170 (7.39%)\n",
      "\n",
      "WARNING: studentInfo has 7,346 duplicate student IDs\n",
      "  This is expected due to multiple module enrollments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate analysis:\")\n",
    "print()\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    n_duplicates = df.duplicated().sum()\n",
    "    \n",
    "    if n_duplicates > 0:\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Total duplicates: {n_duplicates:,} ({n_duplicates/len(df)*100:.2f}%)\")\n",
    "        print()\n",
    "    \n",
    "    quality_report[name]['duplicate_rows'] = int(n_duplicates)\n",
    "\n",
    "if not any(df.duplicated().sum() > 0 for df in datasets.values()):\n",
    "    print(\"No duplicate rows found in any dataset\")\n",
    "    print()\n",
    "\n",
    "duplicates_in_student_info = student_info.duplicated(subset=['id_student'], keep=False).sum()\n",
    "if duplicates_in_student_info > 0:\n",
    "    print(f\"WARNING: studentInfo has {duplicates_in_student_info:,} duplicate student IDs\")\n",
    "    print(\"  This is expected due to multiple module enrollments\")\n",
    "    print()\n",
    "\n",
    "quality_report['studentInfo']['duplicate_students'] = int(duplicates_in_student_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Clean datasets and add derived columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning student_vle...\n",
      "  Added 'week' column derived from 'date'\n",
      "  Week range: -4 to 38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning student_vle...\")\n",
    "\n",
    "if 'week' not in student_vle.columns and 'date' in student_vle.columns:\n",
    "    student_vle['week'] = (student_vle['date'] // 7).astype(int)\n",
    "    print(\"  Added 'week' column derived from 'date'\")\n",
    "else:\n",
    "    print(\"  'week' column already exists\")\n",
    "\n",
    "print(f\"  Week range: {student_vle['week'].min()} to {student_vle['week'].max()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning student_assessment...\n",
      "  All scores within valid range [0, 100]\n",
      "  Rows retained: 173,912 / 173,912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning student_assessment...\")\n",
    "\n",
    "initial_count = len(student_assessment)\n",
    "student_assessment_clean = student_assessment.copy()\n",
    "\n",
    "if 'score' in student_assessment_clean.columns:\n",
    "    invalid_scores = student_assessment_clean['score'].notna() & (\n",
    "        (student_assessment_clean['score'] < 0) | (student_assessment_clean['score'] > 100)\n",
    "    )\n",
    "    n_invalid = invalid_scores.sum()\n",
    "    \n",
    "    if n_invalid > 0:\n",
    "        print(f\"  Found {n_invalid:,} scores outside valid range [0, 100]\")\n",
    "        print(f\"    Setting to NaN\")\n",
    "        student_assessment_clean.loc[invalid_scores, 'score'] = np.nan\n",
    "    else:\n",
    "        print(\"  All scores within valid range [0, 100]\")\n",
    "\n",
    "final_count = len(student_assessment_clean)\n",
    "print(f\"  Rows retained: {final_count:,} / {initial_count:,}\")\n",
    "print()\n",
    "\n",
    "student_assessment = student_assessment_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning student_registration...\n",
      "  Filling 45 missing registration dates with 0\n",
      "  Filling 22,521 missing unregistration dates with 9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning student_registration...\")\n",
    "\n",
    "student_registration_clean = student_registration.copy()\n",
    "\n",
    "if 'date_registration' in student_registration_clean.columns:\n",
    "    missing_reg = student_registration_clean['date_registration'].isnull().sum()\n",
    "    if missing_reg > 0:\n",
    "        print(f\"  Filling {missing_reg:,} missing registration dates with 0\")\n",
    "        student_registration_clean['date_registration'].fillna(0, inplace=True)\n",
    "\n",
    "if 'date_unregistration' in student_registration_clean.columns:\n",
    "    missing_unreg = student_registration_clean['date_unregistration'].isnull().sum()\n",
    "    if missing_unreg > 0:\n",
    "        print(f\"  Filling {missing_unreg:,} missing unregistration dates with 9999\")\n",
    "        student_registration_clean['date_unregistration'].fillna(9999, inplace=True)\n",
    "\n",
    "print()\n",
    "\n",
    "student_registration = student_registration_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "Split students into train and holdout sets for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/test student split...\n",
      "\n",
      "Total students: 28,785\n",
      "Holdout fraction: 0.1\n",
      "Holdout students: 2,878\n",
      "Training students: 25,907\n",
      "\n",
      "Verification:\n",
      "  Train set size: 25,907\n",
      "  Holdout set size: 2,878\n",
      "  Overlap: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating train/test student split...\")\n",
    "print()\n",
    "\n",
    "all_students = student_info['id_student'].unique()\n",
    "n_students = len(all_students)\n",
    "n_holdout = int(n_students * HOLDOUT_STUDENT_FRAC)\n",
    "\n",
    "print(f\"Total students: {n_students:,}\")\n",
    "print(f\"Holdout fraction: {HOLDOUT_STUDENT_FRAC}\")\n",
    "print(f\"Holdout students: {n_holdout:,}\")\n",
    "print(f\"Training students: {n_students - n_holdout:,}\")\n",
    "print()\n",
    "\n",
    "holdout_students = set(np.random.choice(all_students, size=n_holdout, replace=False))\n",
    "train_students = set(all_students) - holdout_students\n",
    "\n",
    "print(f\"Verification:\")\n",
    "print(f\"  Train set size: {len(train_students):,}\")\n",
    "print(f\"  Holdout set size: {len(holdout_students):,}\")\n",
    "print(f\"  Overlap: {len(train_students & holdout_students)}\")\n",
    "print()\n",
    "\n",
    "student_split = {\n",
    "    'train_students': train_students,\n",
    "    'holdout_students': holdout_students,\n",
    "    'n_train': len(train_students),\n",
    "    'n_holdout': len(holdout_students),\n",
    "    'holdout_fraction': HOLDOUT_STUDENT_FRAC,\n",
    "    'random_seed': RNG_SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed datasets...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afcf8a3a3804954872d69d2b9a871c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All files saved to: ../670-Project/data/processed\n",
      "\n",
      "Saved files:\n",
      "  student_info_clean.pkl                   (1.32 MB)\n",
      "  student_vle_clean.pkl                    (447.16 MB)\n",
      "  vle_clean.pkl                            (0.18 MB)\n",
      "  assessments_clean.pkl                    (0.01 MB)\n",
      "  student_assessment_clean.pkl             (6.64 MB)\n",
      "  courses_clean.pkl                        (0.00 MB)\n",
      "  student_registration_clean.pkl           (0.87 MB)\n",
      "  student_split.pkl                        (0.52 MB)\n",
      "  data_quality_report.pkl                  (0.00 MB)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving processed datasets...\")\n",
    "print()\n",
    "\n",
    "save_jobs = [\n",
    "    ('student_info_clean.pkl', student_info),\n",
    "    ('student_vle_clean.pkl', student_vle),\n",
    "    ('vle_clean.pkl', vle),\n",
    "    ('assessments_clean.pkl', assessments),\n",
    "    ('student_assessment_clean.pkl', student_assessment),\n",
    "    ('courses_clean.pkl', courses),\n",
    "    ('student_registration_clean.pkl', student_registration),\n",
    "    ('student_split.pkl', student_split),\n",
    "    ('data_quality_report.pkl', quality_report)\n",
    "]\n",
    "\n",
    "for filename, data in tqdm(save_jobs, desc=\"Saving files\"):\n",
    "    filepath = DATA_PROCESSED_DIR / filename\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "print(\"\\nAll files saved to:\", DATA_PROCESSED_DIR)\n",
    "print()\n",
    "\n",
    "print(\"Saved files:\")\n",
    "for filename, _ in save_jobs:\n",
    "    filepath = DATA_PROCESSED_DIR / filename\n",
    "    size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {filename:40s} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION COMPLETE\n",
      "Processed datasets:\n",
      "  studentInfo: 32,593 rows\n",
      "  studentVle: 10,655,280 rows\n",
      "  vle: 6,364 rows\n",
      "  assessments: 206 rows\n",
      "  studentAssessment: 173,912 rows\n",
      "  courses: 22 rows\n",
      "  studentRegistration: 32,593 rows\n",
      "\n",
      "Student split:\n",
      "  Training: 25,907 students\n",
      "  Holdout: 2,878 students\n",
      "\n",
      "Data quality:\n",
      "  Total missing values: 34,347\n",
      "  Datasets with duplicates: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA PREPARATION COMPLETE\")\n",
    "\n",
    "print(\"Processed datasets:\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"  {name}: {len(df):,} rows\")\n",
    "print()\n",
    "\n",
    "print(\"Student split:\")\n",
    "print(f\"  Training: {len(train_students):,} students\")\n",
    "print(f\"  Holdout: {len(holdout_students):,} students\")\n",
    "print()\n",
    "\n",
    "print(\"Data quality:\")\n",
    "total_missing = sum(\n",
    "    sum(report['missing_values'].values()) \n",
    "    for report in quality_report.values()\n",
    ")\n",
    "print(f\"  Total missing values: {total_missing:,}\")\n",
    "print(f\"  Datasets with duplicates: {sum(1 for r in quality_report.values() if r['duplicate_rows'] > 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
